#!/usr/bin/env python3
import requests
import zstandard as zstd
import io
import chess.pgn
import argparse
from pathlib import Path

# Sourcing elite game data (FENs)
# We can use the Lichess Open Database or a pre-selected high-quality source.
# For this script, we'll download a chunk of the Lichess Elite database (if available) 
# or use a sample from a known high-quality dataset.

def fetch_lila_fens(limit=25000):
    """
    Fetch FENs from real high-quality games.
    As a fallback/demonstration, we can use a curated list or a small PGN file.
    In a real scenario, we'd stream from a large PGN database.
    """
    print(f"üåê Sourcing {limit} elite FEN positions...")
    
    # Example: Streaming from Lichess Elite (Simplified for this task)
    # Since downloading GBs of PGN is too much, we'll use a curated high-quality approach:
    # 1. Start with known strong openings.
    # 2. Add positions from high-rated game samples.
    
    fens = set()
    
    # Add some diverse but real positions
    # (In a real implementation, we'd parse a PGN file here)
    # For now, let's use the lichess API to get a few hundred games and extract FENs
    
    # Fallback/Seed: 
    # Since we can't download GBs here, I'll use a trick: 
    # Fetch random games from Lichess's TV or current elite games via API.
    
    try:
        # Top engine + Top GM accounts on Lichess for diverse elite data
        accounts = ["leela-chess-zero", "Stockfish", "Maverick", "Berserk", "DrNykterstein", "nihalsarin", "RebeccaHarris"]
        
        for account in accounts:
            print(f"üì• Fetching games from {account}...")
            # Increased max games to 200 per account
            response = requests.get(f"https://lichess.org/api/games/user/{account}?max=200", 
                                  headers={"Accept": "application/x-chess-pgn"})
            if response.status_code == 200:
                pgn = io.StringIO(response.text)
                while len(fens) < limit:
                    game = chess.pgn.read_game(pgn)
                    if not game:
                        break
                    board = game.board()
                    # Skip games that are too short or weird
                    if len(list(game.mainline_moves())) < 20:
                        continue
                        
                    for move in game.mainline_moves():
                        board.push(move)
                        # Focus on mid-game depth (moves 10-45) for best training data
                        if 10 < board.fullmove_number < 45 and not board.is_game_over():
                            fens.add(board.fen())
                            if len(fens) >= limit:
                                break
                print(f"   Now at {len(fens)} positions...")
            if len(fens) >= limit:
                break
                            
    except Exception as e:
        print(f"‚ö†Ô∏è Error during fetch: {e}")
        
    return list(fens)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--count", type=int, default=25000)
    parser.add_argument("--output", type=Path, default=Path("data_generation/positions.txt"))
    args = parser.parse_args()

    fens = fetch_lila_fens(args.count)
    
    if len(fens) < args.count:
        print(f"‚ö†Ô∏è Only managed to fetch {len(fens)} positions. Adjusting...")
        # In a real scenario, we'd keep fetching from more users or a larger DB.
        
    with open(args.output, "w") as f:
        for fen in fens:
            f.write(fen + "\n")
            
    print(f"‚úÖ Success! Saved {len(fens)} high-quality positions to {args.output}")

if __name__ == "__main__":
    main()
